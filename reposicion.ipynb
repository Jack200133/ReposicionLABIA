{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.  39.   4. ...  80.  77.   0.]\n",
      " [  0.  46.   2. ...  95.  76.   0.]\n",
      " [  1.  48.   1. ...  75.  70.   0.]\n",
      " ...\n",
      " [  0.  48.   2. ...  84.  86.   0.]\n",
      " [  0.  44.   1. ...  86.  nan   0.]\n",
      " [  0.  52.   2. ...  80. 107.   0.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file = 'framingham.csv'\n",
    "\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "data = df.to_numpy()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8301886792452831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.98      0.91       708\n",
      "         1.0       0.43      0.09      0.15       140\n",
      "\n",
      "    accuracy                           0.83       848\n",
      "   macro avg       0.64      0.53      0.53       848\n",
      "weighted avg       0.78      0.83      0.78       848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TASK 1.2 \n",
    "X = data[:, :-1]  # Todas las columnas excepto la última\n",
    "y = data[:, -1]  # La última columna\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Crear un imputador para llenar los valores faltantes con la media de la columna\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Aplique el imputador a los datos\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Continúe con el escalado y la ingeniería de características polinomiales como antes\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)  # Ajuste el grado según lo desee\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "# Divida los datos en conjuntos de entrenamiento y prueba, ajuste y evalúe el modelo como antes\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=123)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Ajustar el modelo logístico\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Imprimir un informe de clasificación\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8325471698113207\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.98      0.91       708\n",
      "         1.0       0.47      0.10      0.16       140\n",
      "\n",
      "    accuracy                           0.83       848\n",
      "   macro avg       0.66      0.54      0.54       848\n",
      "weighted avg       0.78      0.83      0.78       848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Función sigmoide\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Función de costo\n",
    "def cost_function(X, y, theta):\n",
    "    m = len(y)\n",
    "    h = sigmoid(X @ theta)\n",
    "    epsilon = 1e-5\n",
    "    cost = (1/m)*(((-y).T @ np.log(h + epsilon))-((1-y).T @ np.log(1-h + epsilon)))\n",
    "    return cost\n",
    "\n",
    "# Descenso del gradiente\n",
    "def gradient_descent(X, y, theta, alpha, num_iters):\n",
    "    m = len(y)\n",
    "    J_history = np.zeros(num_iters)\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        theta = theta - (alpha/m) * (X.T @ (sigmoid(X @ theta) - y))\n",
    "        J_history[i] = cost_function(X, y, theta)\n",
    "    \n",
    "    return theta, J_history\n",
    "\n",
    "# Parámetros iniciales\n",
    "m, n = X_train.shape\n",
    "theta_initial = np.zeros(n)\n",
    "alpha = 0.01\n",
    "num_iters = 10000\n",
    "\n",
    "# Ajustar el modelo\n",
    "theta, J_history = gradient_descent(X_train, y_train, theta_initial, alpha, num_iters)\n",
    "\n",
    "# Predecir usando el conjunto de prueba\n",
    "y_test_prob = sigmoid(X_test @ theta)\n",
    "y_test_pred = np.round(y_test_prob)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Imprimir un informe de clasificación\n",
    "report = classification_report(y_test, y_test_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor grado polinomial es: 2\n",
      "Accuracy: 0.8278301886792453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(include_bias=False)),\n",
    "    ('classifier', LogisticRegression(solver='saga', tol=1e-3, max_iter=10))\n",
    "])\n",
    "\n",
    "# Definir los grados de polinomio que desea evaluar\n",
    "polynomial_degrees = [1, 2, 3,4,5,6]  # Reducir el rango de grados polinomiales\n",
    "\n",
    "# Configurar la búsqueda en cuadrícula con validación cruzada\n",
    "param_grid = {'poly__degree': polynomial_degrees}\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "#80 train 10 test 10 valid\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2, random_state=123)\n",
    "X_test , X_valid, y_test, y_valid = train_test_split(X_test, y_test, test_size=0.5, random_state=123)\n",
    "\n",
    "# Ajustar la búsqueda en cuadrícula\n",
    "grid_search.fit(X_valid, y_valid)\n",
    "\n",
    "# Obtener el mejor grado y el mejor modelo\n",
    "best_degree = grid_search.best_params_['poly__degree']\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"El mejor grado polinomial es: {best_degree}\")\n",
    "\n",
    "# Ajustar el mejor modelo\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir usando el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis \n",
    "Basándonos en los resultados obtenidos para el modelo de regresión logística polinomial y el modelo de regresión logística, podemos hacer las siguientes observaciones:\n",
    "\n",
    "1. Precisión y recall:\n",
    "\n",
    "* Para la clase 0 (no sufre paro cardíaco), ambos modelos tienen una precisión y un recall altos. Esto indica que los modelos pueden predecir correctamente la mayoría de los casos en los que un paciente no sufre un paro cardíaco.\n",
    "* Para la clase 1 (sufre paro cardíaco), ambos modelos tienen una precisión baja y un recall aún más bajo. Esto indica que los modelos tienen dificultades para predecir correctamente los casos en los que un paciente sufre un paro cardíaco. La mayoría de las predicciones de paro cardíaco son incorrectas (baja precisión) y muchos casos reales de paro cardíaco no se detectan (bajo recall).\n",
    "\n",
    "2. Ajuste del modelo y complejidad:\n",
    "\n",
    "* El mejor grado polinomial encontrado mediante la validación cruzada es 2. Esto sugiere que un modelo cuadrático puede ser suficiente para capturar la relación entre las variables independientes y la variable dependiente.\n",
    "* La precisión general (accuracy) de ambos modelos es bastante similar, siendo ligeramente mayor en el modelo de regresión logística. Esto sugiere que el modelo polinomial de grado 2 no proporciona un aumento significativo en el rendimiento en comparación con el modelo de regresión logística lineal.\n",
    "\n",
    "3. Sobre los resultados de cross-validation:\n",
    "\n",
    "* El mejor grado polinomial encontrado fue 2, lo que sugiere que un modelo cuadrático puede ser suficiente para capturar la relación entre las variables independientes y la variable dependiente.\n",
    "* La precisión en el mejor modelo polinomial es similar a la precisión de los modelos de regresión logística y logística polinomial sin validación cruzada. Esto indica que la validación cruzada proporciona una estimación razonable del rendimiento del modelo.  \n",
    "\n",
    "\n",
    "En resumen, aunque se encontró que el mejor grado polinomial es 2, el modelo de regresión logística polinomial no ofrece una mejora significativa en la precisión en comparación con el modelo de regresión logística lineal. Ambos modelos tienen un rendimiento similar en términos de precisión y recall en cada clase. Sin embargo, en ambos casos, el rendimiento en la predicción de paros cardíacos (clase 1) es bajo y puede ser necesario explorar otras técnicas o características adicionales para mejorar el rendimiento del modelo en esta clase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
